{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dzivkovi/LLM_RBAC_experiments/blob/main/06_Weaviate_VectorDB_LlamaIndex_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
      "metadata": {
        "id": "307804a3-c02b-4a57-ac0d-172c30ddc851"
      },
      "source": [
        "# LlamaIndex with Weaviate Vector Store"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5508d8ac",
      "metadata": {
        "id": "5508d8ac"
      },
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/vector_stores/WeaviateIndexDemo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b05d5956",
      "metadata": {
        "id": "b05d5956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffed9f4-d201-46bf-c193-614ab3665942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.9.26-py3-none-any.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from llama-index)\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama-index)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Collecting httpx (from llama-index)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Collecting openai>=1.1.0 (from llama-index)\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.3.0)\n",
            "Collecting typing-extensions>=4.5.0 (from llama-index)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->llama-index)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.6)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, h11, deprecated, beautifulsoup4, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.12.2 dataclasses-json-0.6.3 deprecated-1.2.14 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 llama-index-0.9.26 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.6.1 tiktoken-0.5.2 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
      "metadata": {
        "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396"
      },
      "source": [
        "#### Creating a Weaviate Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "08ad68ce",
      "metadata": {
        "id": "08ad68ce"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eccceb71",
      "metadata": {
        "id": "eccceb71"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install weaviate-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6usn_XKUhOE",
        "outputId": "37f8931d-d048-4ba5-8c65-39167abc3e7e"
      },
      "id": "j6usn_XKUhOE",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-3.26.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.31.0)\n",
            "Collecting validators<1.0.0,>=0.21.2 (from weaviate-client)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (41.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2023.11.17)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.21)\n",
            "Installing collected packages: validators, authlib, weaviate-client\n",
            "Successfully installed authlib-1.3.0 validators-0.22.0 weaviate-client-3.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "72a4b618-668d-4713-84c5-6362030e9f19",
      "metadata": {
        "id": "72a4b618-668d-4713-84c5-6362030e9f19"
      },
      "outputs": [],
      "source": [
        "import weaviate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "df8b27e5-5ad5-4dfe-90c7-0cf1f1d1b37f",
      "metadata": {
        "id": "df8b27e5-5ad5-4dfe-90c7-0cf1f1d1b37f"
      },
      "outputs": [],
      "source": [
        "# cloud\n",
        "#resource_owner_config = weaviate.AuthClientPassword(\n",
        "#    username=\"<username>\",\n",
        "#    password=\"<password>\",\n",
        "#)\n",
        "client = weaviate.Client(\n",
        "    \"https://multi-tenancy-og68lbsz.weaviate.network\",\n",
        ")\n",
        "#    auth_client_secret=resource_owner_config,\n",
        "#)\n",
        "\n",
        "# local\n",
        "# client = weaviate.Client(\"http://localhost:8080\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
      "metadata": {
        "id": "8ee4473a-094f-4d0a-a825-e1213db07240"
      },
      "source": [
        "#### Load documents, build the VectorStoreIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0a2bcc07",
      "metadata": {
        "id": "0a2bcc07"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.vector_stores import WeaviateVectorStore\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf37644",
      "metadata": {
        "id": "0cf37644"
      },
      "source": [
        "Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7b7da523",
      "metadata": {
        "id": "7b7da523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8ecc30-96ff-47a3-8ce7-05b27c8280e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-07 19:21:15--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75042 (73K) [text/plain]\n",
            "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
            "\n",
            "\r          data/paul   0%[                    ]       0  --.-KB/s               \rdata/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-01-07 19:21:15 (5.84 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
      "metadata": {
        "id": "68cbd239-880e-41a3-98d8-dbb3fab55431"
      },
      "outputs": [],
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ba1558b3",
      "metadata": {
        "id": "ba1558b3"
      },
      "outputs": [],
      "source": [
        "from llama_index.storage.storage_context import StorageContext\n",
        "\n",
        "# If you want to load the index later, be sure to give it a name!\n",
        "vector_store = WeaviateVectorStore(\n",
        "    weaviate_client=client, index_name=\"LlamaIndex\"\n",
        ")\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")\n",
        "\n",
        "# NOTE: you may also choose to define a index_name manually.\n",
        "# index_name = \"test_prefix\"\n",
        "# vector_store = WeaviateVectorStore(weaviate_client=client, index_name=index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04304299-fc3e-40a0-8600-f50c3292767e",
      "metadata": {
        "id": "04304299-fc3e-40a0-8600-f50c3292767e"
      },
      "source": [
        "#### Query Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "35369eda",
      "metadata": {
        "id": "35369eda"
      },
      "outputs": [],
      "source": [
        "# set Logging to DEBUG for more detailed outputs\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
      "metadata": {
        "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
        "outputId": "c2c00448-3273-4666-8ca0-9781cb31f0dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>The author worked on writing and programming outside of school before college. They wrote short stories and tried writing programs on an IBM 1401 computer. They also got a microcomputer and started programming on it, writing simple games and a word processor. Additionally, the author initially planned to study philosophy in college but later switched to AI.</b>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0123088b",
      "metadata": {
        "id": "0123088b"
      },
      "source": [
        "## Loading the index\n",
        "\n",
        "Here, we use the same index name as when we created the initial index. This stops it from being auto-generated and allows us to easily connect back to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f3e2c654",
      "metadata": {
        "id": "f3e2c654"
      },
      "outputs": [],
      "source": [
        "client = weaviate.Client(\"https://multi-tenancy-og68lbsz.weaviate.network\")\n",
        "\n",
        "# local\n",
        "# client = weaviate.Client(\"http://localhost:8080\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f2e0997c",
      "metadata": {
        "id": "f2e0997c"
      },
      "outputs": [],
      "source": [
        "vector_store = WeaviateVectorStore(\n",
        "    weaviate_client=client, index_name=\"LlamaIndex\"\n",
        ")\n",
        "\n",
        "loaded_index = VectorStoreIndex.from_vector_store(vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bc9a2ad0",
      "metadata": {
        "id": "bc9a2ad0",
        "outputId": "55848472-09cc-4c71-ec57-084aa792d54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>At Interleaf, they added a scripting language inspired by Emacs and made it a dialect of Lisp. They were looking for a Lisp hacker to write things in this scripting language. The author of the text worked at Interleaf and mentioned that their Lisp was the thinnest icing on a giant C cake. The author also mentioned that they didn't know C and didn't want to learn it, so they never understood most of the software at Interleaf. Additionally, the author admitted to being a bad employee and spending much of their time working on a separate project called On Lisp.</b>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# set Logging to DEBUG for more detailed outputs\n",
        "query_engine = loaded_index.as_query_engine()\n",
        "response = query_engine.query(\"What happened at interleaf?\")\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a41a70d",
      "metadata": {
        "id": "3a41a70d"
      },
      "source": [
        "## Metadata Filtering\n",
        "### Can be used to simulate RBAC\n",
        "\n",
        "Let's insert a dummy document, and try to filter so that only that document is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "df6b6d46",
      "metadata": {
        "id": "df6b6d46",
        "outputId": "52935759-2892-4f8b-d12f-b5878ffdfa51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'filename': 'README.md', 'category': 'codebase'}\n",
            "-----\n",
            "\n",
            "Context\n",
            "LLMs are a phenomenal piece of technology for knowledge generation and reasoning.\n",
            "They are pre-trained on large amounts of publicly available data.\n",
            "How do we best augment LLMs with our own private data?\n",
            "We need a comprehensive toolkit to help perform this data augmentation for LLMs.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index import Document\n",
        "\n",
        "doc = Document.example()\n",
        "print(doc.metadata)\n",
        "print(\"-----\")\n",
        "print(doc.text[:293])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "30b0b2e3",
      "metadata": {
        "id": "30b0b2e3"
      },
      "outputs": [],
      "source": [
        "loaded_index.insert(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c1bd18f8",
      "metadata": {
        "id": "c1bd18f8",
        "outputId": "c452a5bf-4f02-4de9-e7af-41d4627e3b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>The name of the file is README.md.</b>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
        "\n",
        "filters = MetadataFilters(\n",
        "    filters=[ExactMatchFilter(key=\"filename\", value=\"README.md\")]\n",
        ")\n",
        "query_engine = loaded_index.as_query_engine(filters=filters)\n",
        "response = query_engine.query(\"What is the name of the file?\")\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "outputId": "c0188e2a-457d-47ea-ac06-4b3cf5fc7012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "_P_uVWcTXXlx"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>The name of the file is README.md.</b>"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
        "\n",
        "filters = MetadataFilters(\n",
        "    filters=[ExactMatchFilter(key=\"category\", value=\"codebase\")]\n",
        ")\n",
        "query_engine = loaded_index.as_query_engine(filters=filters)\n",
        "response = query_engine.query(\"What is the name of the file?\")\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ],
      "id": "_P_uVWcTXXlx"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}