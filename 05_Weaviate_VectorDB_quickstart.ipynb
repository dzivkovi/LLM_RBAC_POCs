{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dzivkovi/LLM_RBAC_experiments/blob/main/05_Weaviate_VectorDB_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9UZV8jVsSC2"
      },
      "source": [
        "# Weaviate Quickstart\n",
        "\n",
        "For more context see https://www.youtube.com/watch?v=Bu9skgCrJY8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/weaviate/recipes.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D08-E4G2sS82",
        "outputId": "7192374b-58b3-4a9b-beae-1784a69477ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'recipes'...\n",
            "remote: Enumerating objects: 927, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 927 (delta 64), reused 51 (delta 39), pack-reused 812\u001b[K\n",
            "Receiving objects: 100% (927/927), 22.86 MiB | 27.03 MiB/s, done.\n",
            "Resolving deltas: 100% (429/429), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install weaviate-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhpzdNHv90Dr",
        "outputId": "b1e5c161-5215-43e5-8a6c-b86407ff554e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-3.26.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.31.0)\n",
            "Collecting validators<1.0.0,>=0.21.2 (from weaviate-client)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting authlib<2.0.0,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (41.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2023.11.17)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client) (2.21)\n",
            "Installing collected packages: validators, authlib, weaviate-client\n",
            "Successfully installed authlib-1.3.0 validators-0.22.0 weaviate-client-3.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R3Bhq94-F_f",
        "outputId": "9b8e1507-4437-4ce5-a4d0-8f4c531ed247"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.9.26-py3-none-any.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.9.1)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from llama_index)\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama_index)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama_index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n",
            "Collecting httpx (from llama_index)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.23.5)\n",
            "Collecting openai>=1.1.0 (from llama_index)\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama_index)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.5.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama_index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama_index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama_index) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (4.66.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama_index) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (1.3.0)\n",
            "Collecting typing-extensions>=4.5.0 (from llama_index)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->llama_index)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (3.6)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama_index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index) (3.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama_index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama_index)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama_index) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, h11, deprecated, beautifulsoup4, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama_index\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.12.2 dataclasses-json-0.6.3 deprecated-1.2.14 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 llama_index-0.9.26 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.6.1 tiktoken-0.5.2 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13jsPtRsSC7"
      },
      "source": [
        "## Overview\n",
        "\n",
        "* What is LlamaIndex?\n",
        "\n",
        "        * LlamaHub (data loaders)\n",
        "\n",
        "* How to setup Weaviate\n",
        "\n",
        "        * Create schema\n",
        "\n",
        "\n",
        "* Adding Data to Weaviate using LlamaIndex\n",
        "\n",
        "        *  Data loader examples\n",
        "\n",
        "* Chunking up your data\n",
        "\n",
        "* Connecting Weaviate instance to LlamaIndex\n",
        "\n",
        "* Simple query engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7d2RmclsSC8"
      },
      "source": [
        "## What is [LlamaIndex](https://www.llamaindex.ai/)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA-AFaJ9sSC9"
      },
      "source": [
        "#### Framework that enables you to connect LLMs and storage providers together seamlessly.\n",
        "#### LlamaIndex 🤝 Weaviate ➡ Ultimate RAG stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFzbkqGUsSC9"
      },
      "source": [
        "#### [LlamaHub](https://llama-hub-ui.vercel.app/): Enables you to connect to a number of external data sources (Notion, Slack, Web pages, and more!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y15_S8qxsSC-"
      },
      "source": [
        "## Setting up Weaviate\n",
        "\n",
        "1. Embedded\n",
        "\n",
        "2. WCS\n",
        "\n",
        "3. Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TfocXzzsSC-"
      },
      "source": [
        "### Embedded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_p0bgRjsSC_"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "\n",
        "# Need the latest version of the Weaviate python client (3.21)\n",
        "\n",
        "client = weaviate.Client(embedded_options=weaviate.EmbeddedOptions())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Fm4xgzsSDC"
      },
      "source": [
        "### WCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q_pVNZysSDC",
        "outputId": "ba85a9d0-394f-41d5-b156-3addceedd677"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classes': [{'class': 'BlogPost',\n",
              "   'description': 'Blog post from the Weaviate website.',\n",
              "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
              "    'cleanupIntervalSeconds': 60,\n",
              "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
              "   'moduleConfig': {'generative-openai': {'model': 'gpt-3.5-turbo'},\n",
              "    'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
              "     'model': 'ada',\n",
              "     'modelVersion': '002',\n",
              "     'type': 'text',\n",
              "     'vectorizeClassName': True}},\n",
              "   'multiTenancyConfig': {'enabled': False},\n",
              "   'properties': [{'dataType': ['text'],\n",
              "     'description': 'Content from the blog post',\n",
              "     'indexFilterable': True,\n",
              "     'indexSearchable': True,\n",
              "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
              "       'vectorizePropertyName': False}},\n",
              "     'name': 'content',\n",
              "     'tokenization': 'word'}],\n",
              "   'replicationConfig': {'factor': 1},\n",
              "   'shardingConfig': {'virtualPerPhysical': 128,\n",
              "    'desiredCount': 1,\n",
              "    'actualCount': 1,\n",
              "    'desiredVirtualCount': 128,\n",
              "    'actualVirtualCount': 128,\n",
              "    'key': '_id',\n",
              "    'strategy': 'hash',\n",
              "    'function': 'murmur3'},\n",
              "   'vectorIndexConfig': {'skip': False,\n",
              "    'cleanupIntervalSeconds': 300,\n",
              "    'maxConnections': 64,\n",
              "    'efConstruction': 128,\n",
              "    'ef': -1,\n",
              "    'dynamicEfMin': 100,\n",
              "    'dynamicEfMax': 500,\n",
              "    'dynamicEfFactor': 8,\n",
              "    'vectorCacheMaxObjects': 1000000000000,\n",
              "    'flatSearchCutoff': 40000,\n",
              "    'distance': 'cosine',\n",
              "    'pq': {'enabled': False,\n",
              "     'bitCompression': False,\n",
              "     'segments': 0,\n",
              "     'centroids': 256,\n",
              "     'trainingLimit': 100000,\n",
              "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
              "   'vectorIndexType': 'hnsw',\n",
              "   'vectorizer': 'text2vec-openai'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import weaviate\n",
        "from google.colab import userdata\n",
        "\n",
        "client = weaviate.Client(\n",
        "  url=\"https://multi-tenancy-og68lbsz.weaviate.network\",  # URL of your Weaviate instance\n",
        "  additional_headers={\n",
        "    \"X-OPENAI-Api-Key\": userdata.get('OPENAI_API_KEY'), # Replace with your OpenAI key\n",
        "  }\n",
        ")\n",
        "\n",
        "client.schema.get()  # Get the schema to test connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMylnAg_sSDD"
      },
      "source": [
        "### Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPnrceD2sSDD",
        "outputId": "638a2a16-255b-4ac1-821a-a54d3e93e413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema was created.\n"
          ]
        }
      ],
      "source": [
        "schema = {\n",
        "   \"classes\": [\n",
        "       {\n",
        "           \"class\": \"BlogPost\",\n",
        "           \"description\": \"Blog post from the Weaviate website.\",\n",
        "           \"vectorizer\": \"text2vec-openai\",\n",
        "           \"moduleConfig\": {\n",
        "               \"generative-openai\": {\n",
        "                    \"model\": \"gpt-3.5-turbo\"\n",
        "                }\n",
        "           },\n",
        "           \"properties\": [\n",
        "               {\n",
        "                  \"name\": \"Content\",\n",
        "                  \"dataType\": [\"text\"],\n",
        "                  \"description\": \"Content from the blog post\",\n",
        "               }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "client.schema.delete_all()\n",
        "\n",
        "client.schema.create(schema)\n",
        "\n",
        "print(\"Schema was created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTUY57bBsSDE"
      },
      "source": [
        "## Adding Data to Weaviate using LlamaIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMRWz84RsSDE"
      },
      "source": [
        "### SimpleWebPageReader: Web scraper that turns HTML to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XzhK-Dk_sSDE"
      },
      "outputs": [],
      "source": [
        "from llama_index import download_loader\n",
        "\n",
        "SimpleWebPageReader = download_loader(\"SimpleWebPageReader\")\n",
        "\n",
        "loader = SimpleWebPageReader()\n",
        "documents = loader.load_data(urls=['https://weaviate.io/blog/llamaindex-and-weaviate'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-8sg9LesSDE"
      },
      "source": [
        "### SimpleDirectoryReader: Read files in your filesystem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hE8lY-dtsSDE"
      },
      "outputs": [],
      "source": [
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "blogs = SimpleDirectoryReader('recipes/integrations/llamaindex/data').load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvffCWZZsSDF"
      },
      "source": [
        "### Creating Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2jE76P1gsSDF"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "\n",
        "parser = SimpleNodeParser()\n",
        "nodes = parser.get_nodes_from_documents(blogs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGlTUrDgsSDF"
      },
      "source": [
        "### Nodes to Weaviate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.vector_stores import WeaviateVectorStore\n",
        "from llama_index import VectorStoreIndex, StorageContext\n",
        "\n",
        "# construct vector store\n",
        "vector_store = WeaviateVectorStore(weaviate_client = client, index_name=\"BlogPost\", text_key=\"content\")\n",
        "\n",
        "# setting up the storage for the embeddings\n",
        "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
        "\n",
        "# set up the index\n",
        "index = VectorStoreIndex(nodes, storage_context = storage_context)"
      ],
      "metadata": {
        "id": "Ru2aFp5nGSSU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTIs3cb4sSDF"
      },
      "source": [
        "### Query in LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x2ZHeFesSDF",
        "outputId": "a52df8f2-df0c-400e-8c21-c103809093b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The intersection between LLMs and search involves several key components. These include retrieval-augmented generation, query understanding, index construction, LLMs in re-ranking, and search result compression. LLMs can be augmented with a search engine to reason about new data without the need for fine-tuning. This approach allows LLMs to generate text based on new information and reduces the parameter count needed for reasoning. LLMs can also be used to formulate search queries by extracting or formulating questions based on prompts. Additionally, LLMs can be used in re-ranking by applying attention over the entire list of potential search results. Finally, LLMs can help reduce the effort required to sift through search results by enabling question answering and summarization techniques.\n"
          ]
        }
      ],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What is the intersection between LLMs and search?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqAckXHjsSDG"
      },
      "source": [
        "## Connecting Weaviate Instance to LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dhXadQPHsSDG"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "from llama_index.readers.weaviate.reader import WeaviateReader\n",
        "\n",
        "# WCS\n",
        "# resource_owner_config = weaviate.AuthClientPassword(\n",
        "#  username = \"username\",\n",
        "#  password = \"password\"\n",
        "#)\n",
        "\n",
        "# initialize reader\n",
        "reader = WeaviateReader(\"https://multi-tenancy-og68lbsz.weaviate.network\") # , auth_client_secret=resource_owner_config)\n",
        "\n",
        "documents = reader.load_data(\n",
        "    class_name=\"BlogPost\",\n",
        "    properties=[\"content\"],\n",
        "    separate_documents=True\n",
        ")\n",
        "\n",
        "\n",
        "# localhost\n",
        "# reader = WeaviateReader(\"http://localhost:8080\")\n",
        "\n",
        "# documents = reader.load_data(\n",
        "#     class_name=\"BlogPost\",\n",
        "#     properties=[\"content\"],\n",
        "#     separate_documents=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOyP4SfRsSDG"
      },
      "source": [
        "### Querying the existing class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYwgSgIJsSDG",
        "outputId": "233f761c-84d7-4097-b764-f8b1cb8e2440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ref2Vec is a machine learning algorithm that generates vector representations of text references. It allows for the creation of a vector representation of a text reference, which can then be used to compare and analyze the similarity between different references. Ref2Vec can be used to identify similar references, classify references, and generate recommendations.\n",
            "Word2Vec is a machine learning algorithm that is used to generate vector representations of words. It is a popular technique in natural language processing and is used to capture the semantic meaning of words by representing them as dense vectors in a high-dimensional space. These vector representations can then be used to measure the similarity between words, perform word analogy tasks, or as input to other machine learning models. Word2Vec has been widely used in various applications such as information retrieval, sentiment analysis, and recommendation systems.\n"
          ]
        }
      ],
      "source": [
        "from llama_index import ListIndex\n",
        "import os\n",
        "\n",
        "#client = weaviate.Client(url=\"https://multi-tenancy-og68lbsz.weaviate.network\")\n",
        "\n",
        "reader = WeaviateReader(\"https://multi-tenancy-og68lbsz.weaviate.network\")\n",
        "\n",
        "query = \"\"\"\n",
        "{\n",
        "  Get {\n",
        "    BlogPost (\n",
        "      bm25: {\n",
        "        query: \"What is ref2vec\"\n",
        "        properties: [\"content\"]\n",
        "      },\n",
        "      limit: 2\n",
        "    ) {\n",
        "      content\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "documents = reader.load_data(graphql_query=query, separate_documents=True)\n",
        "\n",
        "index = ListIndex.from_documents(documents)\n",
        "\n",
        "\n",
        "query_engine = index.as_query_engine(response_mode=\"compact\")\n",
        "response = query_engine.query(\"what is ref2vec\")\n",
        "print(response)\n",
        "\n",
        "response = query_engine.query(\"what is word2vec\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32n5N62ASs27"
      },
      "source": [
        "### Filtering to restrict access"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.llamaindex.ai/en/stable/examples/vector_stores/WeaviateIndexDemo.html\n"
      ],
      "metadata": {
        "id": "30iJUmO_Sa-n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}